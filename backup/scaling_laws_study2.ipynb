{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b14aaa1-5633-4b9d-935e-e437612b5d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from matplotlib.colors import ListedColormap\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from irt import *\n",
    "data_path = '/llmthonskdir/felipe/download_openllmlb/'\n",
    "\n",
    "def filter(s):\n",
    "    try:s = s.split(\"/\")[1]\n",
    "    except: s = s\n",
    "    try:s = s.split(\"__\")[1]\n",
    "    except: s = s\n",
    "    return s.lower().replace(\"-hf\",\"\").replace(\"_\",\"\").replace(\"-\",\"\")\n",
    "    \n",
    "def search(s, s_list):\n",
    "    scores = [fuzz.token_sort_ratio(filter(s), filter(s_try)) for s_try in s_list]\n",
    "    return [s_list[np.argmax(scores)], np.max(scores)]\n",
    "\n",
    "scenarios = ['harness_arc_challenge_25', 'harness_gsm8k_5', 'harness_hellaswag_10', 'harness_truthfulqa_mc_0', 'harness_winogrande_5', 'harness_hendrycksTest_abstract_algebra_5', 'harness_hendrycksTest_anatomy_5', 'harness_hendrycksTest_astronomy_5', 'harness_hendrycksTest_business_ethics_5', 'harness_hendrycksTest_clinical_knowledge_5', 'harness_hendrycksTest_college_biology_5', 'harness_hendrycksTest_college_chemistry_5', 'harness_hendrycksTest_college_computer_science_5', 'harness_hendrycksTest_college_mathematics_5', 'harness_hendrycksTest_college_medicine_5', 'harness_hendrycksTest_college_physics_5', 'harness_hendrycksTest_computer_security_5', 'harness_hendrycksTest_conceptual_physics_5', 'harness_hendrycksTest_econometrics_5', 'harness_hendrycksTest_electrical_engineering_5', 'harness_hendrycksTest_elementary_mathematics_5', 'harness_hendrycksTest_formal_logic_5', 'harness_hendrycksTest_global_facts_5', 'harness_hendrycksTest_high_school_biology_5', 'harness_hendrycksTest_high_school_chemistry_5', 'harness_hendrycksTest_high_school_computer_science_5', 'harness_hendrycksTest_high_school_european_history_5', 'harness_hendrycksTest_high_school_geography_5', 'harness_hendrycksTest_high_school_government_and_politics_5', 'harness_hendrycksTest_high_school_macroeconomics_5', 'harness_hendrycksTest_high_school_mathematics_5', 'harness_hendrycksTest_high_school_microeconomics_5', 'harness_hendrycksTest_high_school_physics_5', 'harness_hendrycksTest_high_school_psychology_5', 'harness_hendrycksTest_high_school_statistics_5', 'harness_hendrycksTest_high_school_us_history_5', 'harness_hendrycksTest_high_school_world_history_5', 'harness_hendrycksTest_human_aging_5', 'harness_hendrycksTest_human_sexuality_5', 'harness_hendrycksTest_international_law_5', 'harness_hendrycksTest_jurisprudence_5', 'harness_hendrycksTest_logical_fallacies_5', 'harness_hendrycksTest_machine_learning_5', 'harness_hendrycksTest_management_5', 'harness_hendrycksTest_marketing_5', 'harness_hendrycksTest_medical_genetics_5', 'harness_hendrycksTest_miscellaneous_5', 'harness_hendrycksTest_moral_disputes_5', 'harness_hendrycksTest_moral_scenarios_5', 'harness_hendrycksTest_nutrition_5', 'harness_hendrycksTest_philosophy_5', 'harness_hendrycksTest_prehistory_5', 'harness_hendrycksTest_professional_accounting_5', 'harness_hendrycksTest_professional_law_5', 'harness_hendrycksTest_professional_medicine_5', 'harness_hendrycksTest_professional_psychology_5', 'harness_hendrycksTest_public_relations_5', 'harness_hendrycksTest_security_studies_5', 'harness_hendrycksTest_sociology_5', 'harness_hendrycksTest_us_foreign_policy_5', 'harness_hendrycksTest_virology_5', 'harness_hendrycksTest_world_religions_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d36f43b-9edd-46db-ab8c-a963dcf24ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = 'harness_arc_challenge_25'\n",
    "fam=0\n",
    "n_fam = 17\n",
    "cmap = ListedColormap(plt.get_cmap('tab20').colors[:n_fam])  # Ensure unique colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ab05ed-c9ce-4040-87e1-c584926e483e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92960e062c0473ab23b79f158d7db45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for scenario in scenarios:\n",
    "    for fam in tqdm(range(17)):\n",
    "        ###\n",
    "        with open('lb.pickle', 'rb') as handle:\n",
    "            lb_data1 = pickle.load(handle)\n",
    "        with open(data_path+'scaling_laws/old_leaderboard_processed_20240630.pickle', 'rb') as handle:\n",
    "            lb_data2 = pickle.load(handle)\n",
    "        scaling_base = pd.read_csv(data_path+'scaling_laws/base_llm_benchmark_eval.csv')\n",
    "        scaling_inst = pd.read_csv(data_path+'scaling_laws/instruct_llm_benchmark_eval.csv')\n",
    "        scaling_data = pd.concat((scaling_base, scaling_inst))\n",
    "        \n",
    "        ###\n",
    "        models_lb_tb = lb_data1['models']\n",
    "        models_lb_tb = [filter(m) for m in models_lb_tb]\n",
    "        models_lb_scaling = lb_data2[scenario]['models']\n",
    "        models_lb_scaling = [filter(m) for m in models_lb_scaling]\n",
    "        models_scaling = list(scaling_data.Model)\n",
    "        models_scaling = [filter(m) for m in models_scaling]\n",
    "        ind = [i for i,m in enumerate(models_lb_tb) if m not in models_lb_scaling]\n",
    "        models_lb_tb = np.array(models_lb_tb)[ind].tolist()\n",
    "        lb_data1['data'][scenario]['correctness'] = lb_data1['data'][scenario]['correctness'].T[ind]\n",
    "        models_lb = models_lb_scaling+models_lb_tb\n",
    "        \n",
    "        ###\n",
    "        scaling_data = scaling_data.loc[[m in models_lb_scaling for m in models_scaling]]\n",
    "        scaling_data['logFLOPs'] = np.log2(scaling_data.loc[:,['FLOPs (1E21)']])\n",
    "        scaling_data = scaling_data.loc[:,['Model','Model Family', 'logFLOPs', 'Model Size (B)']]\n",
    "        scaling_data = scaling_data.rename(columns={'Model':'models', 'Model Family': \"family\"})\n",
    "        scaling_data = scaling_data.sort_values(by=['family', 'logFLOPs']).reset_index(drop=True)\n",
    "        scaling_data = scaling_data.loc[~np.array(np.isnan(scaling_data.loc[:,['logFLOPs']])).squeeze()]\n",
    "        scaling_data = scaling_data.groupby('family').filter(lambda x: len(x) > 1)\n",
    "        \n",
    "        ###\n",
    "        families = np.unique(scaling_data.family).tolist()\n",
    "        test_fam = [families[fam]]\n",
    "        train_fam = [f for f in families if f not in test_fam]\n",
    "        ind = [i for i,m in enumerate(models_lb) if m not in [filter(m) for m in scaling_data.loc[scaling_data.family==test_fam[0]].models]]\n",
    "        Y = np.vstack((lb_data2[scenario]['correctness'], lb_data1['data'][scenario]['correctness']))\n",
    "        irt = IRT([1])\n",
    "        irt.fit(Y[ind], tol=1e-2, verbose=False)\n",
    "    \n",
    "        ###\n",
    "        models_scaling = list(scaling_data.models)\n",
    "        models_scaling = [filter(m) for m in models_scaling]\n",
    "        thetas = np.array(len(models_scaling)*[np.nan])\n",
    "        models_test = np.array(models_lb)[[i for i in range(Y.shape[0]) if i not in ind]].tolist()\n",
    "        models_train = [m for m in models_scaling if m not in models_test]\n",
    "        theta_train = irt.Theta.squeeze()[[np.argmax(np.array(models_lb)[ind]==m) for m in models_train]]#[[i for i,m in enumerate(np.array(models_lb)[ind].tolist()) if m in models_train]]\n",
    "        theta_test = irt.fit_theta(Y[[i for i in range(Y.shape[0]) if i not in ind]], list(range(Y.shape[1]))).squeeze()\n",
    "        thetas[[np.argmax(np.array(models_scaling)==m) for m in models_train]] = theta_train\n",
    "        thetas[[np.argmax(np.array(models_scaling)==m) for m in models_test]] = theta_test\n",
    "        scaling_data['thetas']=thetas\n",
    "        \n",
    "        \n",
    "        ###\n",
    "        test_ind = np.array([f in test_fam for f in scaling_data.family])\n",
    "        train_ind = ~np.array(test_ind)\n",
    "        test_data = scaling_data.loc[test_ind]\n",
    "        train_data = scaling_data.loc[train_ind]\n",
    "    \n",
    "        mod = smf.ols(formula='thetas ~ logFLOPs + family - 1', data=train_data)\n",
    "        mod = mod.fit()\n",
    "        \n",
    "        intercept = np.array(test_data.thetas)[0] - (mod.params['logFLOPs']*np.array(test_data.logFLOPs))[0]\n",
    "        preds = np.array(intercept + mod.params['logFLOPs']*np.array(test_data.logFLOPs)).tolist()[1:]\n",
    "        trues = np.array(test_data.thetas).tolist()[1:]\n",
    "        plt.plot(trues, preds, 'o', label=test_fam[0], color=cmap(fam))\n",
    "    plt.title(scenario)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "29665141-23b8-4ad5-ba5a-2b0bfd580099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(families)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccf435c-c5df-4127-b73e-428fb61a2bce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd1dd90-a29b-415c-ab97-352fdaf23165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
